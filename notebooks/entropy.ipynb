{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What's an intuitive way to think of cross entropy\n",
    "\n",
    "**Source:**\n",
    "\n",
    "> - [What's an intuitive way to think of cross entropy](https://www.quora.com/Whats-an-intuitive-way-to-think-of-cross-entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Gentle Introduction to Information Entropy\n",
    "\n",
    "**Source:**\n",
    "\n",
    ">- [A Gentle Introduction to Information Entropy](https://machinelearningmastery.com/what-is-information-entropy/)\n",
    "\n",
    "## What is information theory\n",
    "\n",
    "Information theory is field of study concerned with quantifying information for communication.\n",
    "\n",
    "*信息论是涉及量化沟通信息的研究领域.*\n",
    "\n",
    "A foundational concept from information is the quantification of the amount of information in things like events, random variables, and distribution.\n",
    "\n",
    "*信息的一个基本概念是对诸如事件, 随机变量和分布的信息量的量化.*\n",
    "\n",
    "> *Why unify information theory and machine learning? Because they are two side of the ame coin. Information theory and machine learning still alone together.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the information for an event\n",
    "\n",
    "Quantifying information is the foundation of field of information theory.\n",
    "\n",
    "The intuition behind quantifying information is the idea of measuring how much surprise there is in an event. Those events that rare (low probability) are more surprising and therefore have more information those events that there are common (high probability).\n",
    "\n",
    "- **Low probability event:** High information (surprising).\n",
    "- **High probability event:** Low information (unsurprising).\n",
    "\n",
    "Rare events are more uncertain or more surprising and require more information to represent them than common events.\n",
    "\n",
    "We can calculate the amount of information there is in an event using the probability of the event. This is called *\"Shannon information\", \"self-information\"*, or simply the *\"information\"*, and can be calculated for a discrete event $x$ as follows:\n",
    "\n",
    "- $information(x) = -\\log_2(p(x))$\n",
    "\n",
    "Where $p(x)$ is the probability of the event $x$.\n",
    "\n",
    "The choice of the 2-base logarithm means that the units of information measure is in bits(binary digits).\n",
    "\n",
    "The calculate of information is often written as $h()$ for example:\n",
    "\n",
    "- $h(x) = -\\log_2(p(x))$\n",
    "\n",
    "The negative sign ensures that the result is always positive or zero.\n",
    "\n",
    "Information will be zero when the probability of an event is $1.0$ or a certainty, e.g. there is no surprise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make this concrete with some examples.\n",
    "\n",
    "Consider a flip of a single fair coin. The probability of heads(and tails) is 0.5. We can calculate the information for flipping a head in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T03:20:12.817600Z",
     "start_time": "2019-11-12T03:20:12.813600Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-12T03:36:42.021001Z",
     "start_time": "2019-11-12T03:36:41.976001Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p(x)=0.5, information: 1.0\n"
     ]
    }
   ],
   "source": [
    "p = 0.5\n",
    "h = -np.log2(p)\n",
    "print(f'p(x)={p}, information: {h}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the Entropy for a Random Variable\n",
    "\n",
    "$\n",
    "H(X)=-\\displaystyle\\sum_{k \\in K} p_k \\log(p_k)\n",
    "$\n",
    "\n",
    "上面的公式含义是, $H(X)$ 表示随机变量 $X$ 的熵, 它等于随机变量 $X$ 的 $K$ 种状态下, 每种状态 $k$ 的概率 $p_k$ 乘以 每种状态 $k$ 的概率的对数 $\\log(p_k)$.\n",
    "\n",
    "The lowest entropy is calculated for random variable that has a single event with a probability of 1.0, a certainly.\n",
    "\n",
    "*随机变量熵的最小值为 $0$, 也就是当随机变量只有一个事件, 换句话说就是该随机变量的概率为 $[1]$. 带入公式很容易得到熵的结果为 $0$*\n",
    "\n",
    "The largest entropy for a random variable will be if all events are equally likely.\n",
    "\n",
    "*当随机变量中的各种状态 $k \\in K$ 的概率相等(均匀分布), 此时该随机变量的熵值最大(从下图可以直观的观察到).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-21T08:23:32.718690Z",
     "start_time": "2019-11-21T08:23:32.714690Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-21T09:51:03.219309Z",
     "start_time": "2019-11-21T09:51:03.091309Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prob_1 = np.linspace(.1, .9, 5)\n",
    "prob_2 = 1 - prob_1\n",
    "pair_prob = np.vstack((prob_1, prob_2))\n",
    "entropy = pair_prob * np.log2(pair_prob)\n",
    "entropy = -1 * np.sum(entropy, axis=0)\n",
    "x = np.arange(len(entropy))\n",
    "\n",
    "plt.xticks(ticks=x, labels=np.array2string(pair_prob.T)[1:-1].split('\\n '))\n",
    "plt.plot(x, entropy)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Gentle Introduction to Cross-Entropy for Machine Learning\n",
    "\n",
    "**Source:**\n",
    "\n",
    "> - [A Gentle Introduction to Cross-Entropy for Machine Learning](https://machinelearningmastery.com/cross-entropy-for-machine-learning/)\n",
    "\n",
    "**Cross-Entropy:** builds upon the idea of entropy from information theory and calculates the number of bits required to represent or transmit an average event from on distribution compared to another distribution.\n",
    "\n",
    "*交叉熵建立在信息论的熵概念之上, 用于计算一个分布中的平均事件用另外一个分布来代表或传输所需的位数(bits)*\n",
    "\n",
    "The intuition for this definition comes if we consider a target or underlying probability distribution P and an approximation of the target distribution Q, the cross-entropy of Q from P is the number of additional bits to represent an event using Q instead of P.\n",
    "\n",
    "*直觉上来讲, 如果我们假设一个目标概率分布为 P 和一个接近或类似该目标的概率分布 Q, 则交叉熵表示的是用 Q 来代表 P 中的一个事件所需要的位数(bits).*\n",
    "\n",
    "$H(P,Q) = -\\displaystyle\\sum_{x \\in P} P(x) \\log(Q(x))$\n",
    "\n",
    "如果 P 和 Q 分布完全一致, 则交叉熵等于 P 或 Q 的熵.\n",
    "\n",
    "> **Note:** this notation looks a lot like the joint probability, or more specifically, the joint entropy between P and Q. This is misleading as we scoring the difference between probability distributions with cross-entropy. Whereas, joint entropy is a different concept that uses the same notation and instead calculates the uncertainly across two(or more) random variables.\n",
    "\n",
    "> *__注意:__* 上面的公式看起来很像联合概率的公式, 或者更具体的说, 是 P 和 Q 的联合熵. 这是一个误导, 交叉熵是用来给概率分布间的不同来打分的. 而联合熵是另一个概念, 它表示的是两个(或更多)的随机变量间的不确定性.\n",
    "\n",
    "The cross-entropy is not symmetrical, meaning that:\n",
    "\n",
    "$H(P,Q) \\neq H(Q,P)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Entropy vs. KL Divergence\n",
    "\n",
    "交叉熵与 KL 散度\n",
    "\n",
    "The KL Divergence is the average number of extra bits need to encode the data, due to the fact that we used distribution Q to encode the data instead of the true distribution P.\n",
    "\n",
    "*KL 散度是基于我们使用分布 Q 代替真实的分布 P 去加密数据, 所需要的额外的位数(bits)的平均值.*\n",
    "\n",
    "- **Cross_Entropy:** Average number of total bits to represent an event from Q instead of P.\n",
    "- **Relative Entropy(KL Divergence):** Average number of extra bits to represent an event from Q instead of P.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Entropy as Loss Function\n",
    "\n",
    "Each example has a know class label with a probability of 1.0, and a probability with 0.0 for all other labels. A model can estimate the probability of an example belonging to each class label. Cross-Entropy can then be used to calculate the difference between the two probability distribution.\n",
    "\n",
    "As such, we can map the classification of one example onto the idea of random variable with a probability distribution as follows:\n",
    "\n",
    "- **Random Variable:** The example for which we require a predicted class label. (*__随机变量:__ 我们需要去预测类标签的样本*)\n",
    "- **Events:** Each class label that could be predicted. (*__事件:__ 可预测的每个类标签*)\n",
    "\n",
    "在分类问题中, 我们分别用 $y$ 和 $\\hat{y}$ 表示实际概率和预测概率.\n",
    "\n",
    "- **Expected Probability($y$):** 某一个样本的每个分类的实际概率.\n",
    "- **Predicted Probability($\\hat{y}$):** 通过模型得到的某一个样本的每个分类的预测概率.\n",
    "\n",
    "某一个样本真实的分类概率分布可以表示为 $P$, 其预测的分类概率分布可以表示为 $Q$\n",
    "\n",
    "$H(P,Q)=-\\displaystyle\\sum_{x \\in X} P(x) \\log(Q(x))$\n",
    "\n",
    "对于二分类问题交叉熵的公式可以表示为:\n",
    "\n",
    "$H(P,Q)=-(P(class0)\\log(Q(class0)) + P(class1)\\log(Q(class1)))$\n",
    "\n",
    "在二分类问题中, 我们通常采用伯努利最为概率预测模型, 因此分类为 1 的标签将作为预测结果, 分类为 0 的标签为 1 - 预测结果, 可以表示如下:\n",
    "\n",
    "- **Predicted $P(class1) = \\hat{y}$**\n",
    "- **Predicted $P(class0) = 1 - \\hat{y}$**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Entropy for Class Label\n",
    "\n",
    "假设我们有一个 2 分类问题, 用性别来分类, 类别分别是\"男\"和\"女\", 那么对于某一个样本它的性别是\"男\", 我们可以用 [1, 0] 来表示它的概率分布, 如果性别是\"女\", 则用 [0,1] 来表示概率分布.\n",
    "\n",
    "在上面的描述中, 随机变量是\"性别\", 事件分别是\"男\"和\"女\", 概率分布 P 在性别是\"男\"的情况下, 表示为 [1, 0], 在\"女\"的情况下 [0, 1].\n",
    "\n",
    "现在我们假设有这么一条性别是\"男\"的样本, 预测结果为 0.8, 那么交叉熵的计算过程如下:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-24T14:13:00.985495Z",
     "start_time": "2019-11-24T14:13:00.979818Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-24T14:33:58.421704Z",
     "start_time": "2019-11-24T14:33:58.407445Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3219, 0.3219)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cross_entropy(p, q, est=1e-15):\n",
    "    log2_q = np.log2(q + est)\n",
    "    k = p * log2_q\n",
    "    return round(-1 * k.sum(), 4)\n",
    "    \n",
    "# 真实的分类概率分布\n",
    "p = np.array([1, 0])\n",
    "# 预测的分类概率分布\n",
    "q = np.array([0.8, 0.2])\n",
    "# 交叉熵\n",
    "ce = -1 * p[0] * np.log2(q[0]) + p[1] * np.log2(q[1])\n",
    "round(ce, 4), cross_entropy(p, q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An introduction to entropy, cross entropy and KL divergence in machine learning\n",
    "\n",
    "**Source:**\n",
    "\n",
    "> - [An introduction to entropy, cross entropy and KL divergence in machine learning](https://adventuresinmachinelearning.com/cross-entropy-kl-divergence/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Information Gain and Mutual Information for Machine Learning\n",
    "\n",
    "**Source:**\n",
    "\n",
    "> - (Information Gain and Mutual Information for Machine Learning)[https://machinelearningmastery.com/information-gain-and-mutual-information/]\n",
    "\n",
    "$\n",
    "I(X;Y) = H(Y) - H(Y|X)\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to Calculate the KL Divergence for Machine Learning\n",
    "\n",
    "**Source:**\n",
    "\n",
    "> - (How to Calculate the KL Divergence for Machine Learning)[https://machinelearningmastery.com/divergence-between-probability-distributions/]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "568px",
    "left": "301px",
    "top": "143px",
    "width": "245px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
